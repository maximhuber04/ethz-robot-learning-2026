{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfac88e5",
   "metadata": {},
   "source": [
    "# Exercise 2: PyTorch core\n",
    "\n",
    "In this exercise you’ll build core PyTorch “muscle memory” that you’ll reuse in basically every model you write:\n",
    "\n",
    "- **Autograd**: how gradients are created, how they accumulate, and how to compute gradients for one or multiple inputs.\n",
    "- **Dataloading**: writing small `Dataset`s, using `DataLoader`, and custom `collate_fn`.\n",
    "- **Optimizers**: implementing **AdamW** updates from scratch (state, bias correction, weight decay).\n",
    "- **Training basics**: a clean single training step.\n",
    "- **Initialization**: fan-in/out and common initializers (Xavier / Kaiming), plus a helper to init `nn.Linear`.\n",
    "\n",
    "As before: fill in all `TODO`s without changing function names or signatures.\n",
    "When debugging, print shapes/dtypes/devices, and write tiny sanity checks (e.g. compare to PyTorch’s built-ins).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0145b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e000b",
   "metadata": {},
   "source": [
    "## Autograd fundamentals\n",
    "\n",
    "PyTorch builds a computation graph when you apply operations to tensors with `requires_grad=True`.\n",
    "Calling `backward()` (or `torch.autograd.grad`) computes gradients by traversing that graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419608fc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Key concepts\n",
    "- **Leaf tensor**: a tensor created by you (not the result of an operation) with `requires_grad=True`. Leaf tensors can store gradients in `.grad`.\n",
    "- **Gradient accumulation**: calling `backward()` adds into `.grad` (it does not overwrite). You must reset gradients between steps/calls.\n",
    "- **`torch.autograd.grad` vs `.backward()`**\n",
    "  - `torch.autograd.grad(f, x)` returns `df/dx` directly and does not write into `x.grad` unless you explicitly do so.\n",
    "  - `f.backward()` writes gradients into `.grad` of leaf tensors.\n",
    "\n",
    "In the next functions you’ll compute gradients for a simple scalar function such as `f(x) = sum(x^2)` using both APIs.\n",
    "\n",
    "### `torch.no_grad()`\n",
    "Wrap inference-only code to avoid tracking gradients and building graphs:\n",
    "- saves memory\n",
    "- speeds up evaluation\n",
    "\n",
    "### `detach()`\n",
    "`y = x.detach()` returns a tensor that shares data with `x` but is **not connected** to the autograd graph.\n",
    "This is useful when you want to treat something as a constant target.\n",
    "\n",
    "### `model.train()` vs `model.eval()`\n",
    "- `train()` enables training behavior (e.g. dropout active, batchnorm updates running stats).\n",
    "- `eval()` enables inference behavior (e.g. dropout off, batchnorm uses running stats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7724fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], requires_grad=True), tensor([2., 4., 6.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grad_with_autograd_grad(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute gradient of f(x) = sum(x^2) using torch.autograd.grad\n",
    "\n",
    "    Requirements:\n",
    "    - Do not call .backward().\n",
    "    - x should require grad inside the function (don't assume it does).\n",
    "    - Must return df/dx\n",
    "    \"\"\"\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    f = torch.sum(x ** 2)\n",
    "    grad = torch.autograd.grad(f, x)[0]\n",
    "    return grad\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "gradient = grad_with_autograd_grad(x)\n",
    "x, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0d32cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], requires_grad=True), tensor([2., 4., 6.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grad_with_backward(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute gradient of f(x) = sum(x^2) using .backward().\n",
    "\n",
    "    Requirements:\n",
    "    - Must return df/dx\n",
    "    - Must not leak gradients across calls (watch x.grad accumulation)\n",
    "    \"\"\"\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    f = torch.sum(x ** 2)\n",
    "    f.backward()\n",
    "    return x.grad\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "gradient = grad_with_backward(x)\n",
    "x, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec40995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], requires_grad=True),\n",
       " tensor([ 6.,  9., 12.]),\n",
       " tensor([4., 5., 6.], requires_grad=True),\n",
       " tensor([1., 2., 3.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grad_wrt_multiple_inputs(\n",
    "    a: torch.Tensor, b: torch.Tensor,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Compute gradients w.r.t. multiple inputs. The function is f(a, b) = sum(a^2 + ab).\n",
    "\n",
    "    Return:\n",
    "        (df/da, df/db)\n",
    "\n",
    "    Requirements:\n",
    "    - Use torch.autograd.grad\n",
    "    - Ensure both a and b require grad in this function.\n",
    "    \"\"\"\n",
    "    a = a.clone().detach().requires_grad_(True)\n",
    "    b = b.clone().detach().requires_grad_(True)\n",
    "    f = torch.sum(a ** 2 + a * b)\n",
    "    da, db = torch.autograd.grad(f, [a, b])\n",
    "    return da, db\n",
    "\n",
    "a = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "b = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
    "da, db = grad_wrt_multiple_inputs(a, b)\n",
    "a, da, b, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfbe29",
   "metadata": {},
   "source": [
    "## Dataloading\n",
    "\n",
    "In PyTorch, a `Dataset` defines how to fetch a *single* training example, and a `DataLoader` handles:\n",
    "- batching\n",
    "- shuffling\n",
    "- parallel workers\n",
    "- optional custom batching logic via `collate_fn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a026b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### `Dataset` in one sentence\n",
    "A `Dataset` only needs:\n",
    "- `__len__`: number of items\n",
    "- `__getitem__`: return one item (e.g. `(x, y)`)\n",
    "\n",
    "### Why `collate_fn` matters\n",
    "The default DataLoader collation stacks items along a new batch dimension.\n",
    "That works for fixed-size tensors, but it breaks for **variable-length sequences**.\n",
    "\n",
    "So we’ll implement padding ourselves:\n",
    "- Convert a list of 1D token sequences into a padded tensor `(B, T_max)`\n",
    "- Track `lengths` and a `padding_mask`\n",
    "\n",
    "### Mask convention for padding\n",
    "For padding masks in this exercise:\n",
    "- `padding_mask[b, t] == True` means **this is padding / invalid**\n",
    "- `padding_mask[b, t] == False` means **this is a real token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dbd7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09ab0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorPairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Minimal dataset wrapping (x, y).\n",
    "\n",
    "    x: (N, ...)\n",
    "    y: (N, ...)\n",
    "\n",
    "    N is the number of samples. The dataset should return tuples of (x[i], y[i]).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(self.x.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return (self.x[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e71e02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextTokenDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Next-token prediction dataset.\n",
    "\n",
    "    Given tokens of shape (N, T), produce:\n",
    "      input_ids  = tokens[:, :-1]\n",
    "      target_ids = tokens[:, 1:]\n",
    "\n",
    "    Return per item:\n",
    "      (input_ids, target_ids)\n",
    "\n",
    "    Notes:\n",
    "    - Returned tensors should be 1D of length (T-1).\n",
    "    - dtype should remain integer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokens: torch.Tensor):\n",
    "        self.tokens = tokens\n",
    "        self.N = tokens.shape[0]\n",
    "        self.T = tokens.shape[1]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        input_ids  = self.tokens[idx, :-1]\n",
    "        target_ids = self.tokens[idx, 1:]\n",
    "        return input_ids, target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d5d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCropSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Sequence dataset that returns random crops of fixed length.\n",
    "\n",
    "    tokens: (N, T_total)\n",
    "    crop_len: L\n",
    "\n",
    "    For each __getitem__:\n",
    "      - sample a start index s so that s+L <= T_total\n",
    "      - return tokens[idx, s:s+L]\n",
    "\n",
    "    Requirements:\n",
    "    - Use a torch.Generator for deterministic behavior if seed is provided.\n",
    "    - Do NOT use Python's random module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokens: torch.Tensor, crop_len: int, seed: int | None = None):\n",
    "        self.tokens = tokens\n",
    "        self.crop_len = crop_len\n",
    "        self.generator = torch.Generator()\n",
    "        if seed is not None:\n",
    "            self.generator.manual_seed(seed)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.tokens.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        T_total = self.tokens.shape[1]\n",
    "        s = torch.randint(0, T_total - self.crop_len + 1, (1,), generator=self.generator).item()\n",
    "        return self.tokens[idx, s:s + self.crop_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73593f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class PaddedBatch:\n",
    "    \"\"\"\n",
    "    A padded batch for variable-length sequences.\n",
    "\n",
    "    tokens: LongTensor (B, T_max)\n",
    "    lengths: LongTensor (B,)\n",
    "    padding_mask: BoolTensor (B, T_max) where True means \"this is padding\"\n",
    "    \"\"\"\n",
    "\n",
    "    tokens: torch.Tensor\n",
    "    lengths: torch.Tensor\n",
    "    padding_mask: torch.Tensor\n",
    "\n",
    "\n",
    "def pad_1d_sequences(seqs: list[torch.Tensor], pad_value: int = 0) -> PaddedBatch:\n",
    "    \"\"\"\n",
    "    Pad a list of 1D integer tensors to the same length.\n",
    "\n",
    "    Requirements:\n",
    "    - Return PaddedBatch(tokens, lengths, padding_mask)\n",
    "    - padding_mask[b, t] == True iff t >= lengths[b]\n",
    "    - tokens should be dtype long, if not cast them\n",
    "    \"\"\"\n",
    "    lengths = torch.tensor([s.shape[0] for s in seqs], dtype=torch.long)\n",
    "    T_max = int(lengths.max())\n",
    "    B = len(seqs)\n",
    "\n",
    "    tokens = torch.full((B, T_max), pad_value, dtype=torch.long)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        tokens[i, :lengths[i]] = seq.long()\n",
    "\n",
    "    # True where position t >= sequence length (i.e. is padding)\n",
    "    t_idx = torch.arange(T_max).unsqueeze(0)   # (1, T_max)\n",
    "    padding_mask = t_idx >= lengths.unsqueeze(1) # (B, T_max)\n",
    "\n",
    "    return PaddedBatch(tokens=tokens, lengths=lengths, padding_mask=padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2df849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_next_token_batch(\n",
    "    batch: list[tuple[torch.Tensor, torch.Tensor]], pad_value: int = 0\n",
    ") -> dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Collate for NextTokenDataset samples that may have variable lengths.\n",
    "\n",
    "    batch: list of (input_ids, target_ids), each 1D\n",
    "\n",
    "    Return dict with:\n",
    "      - input_ids: (B, T_max)\n",
    "      - target_ids: (B, T_max)\n",
    "      - attention_mask: (B, T_max) where True means \"keep\" (NOT padding)\n",
    "      - padding_mask: (B, T_max) where True means \"padding\"\n",
    "\n",
    "    Requirements:\n",
    "    - pad input_ids and target_ids consistently\n",
    "    - attention_mask is the logical NOT of padding_mask\n",
    "    \"\"\"\n",
    "    input_seqs, target_seqs = zip(*batch)\n",
    "\n",
    "    padded_inputs  = pad_1d_sequences(list(input_seqs),  pad_value)\n",
    "    padded_targets = pad_1d_sequences(list(target_seqs), pad_value)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\":      padded_inputs.tokens,\n",
    "        \"target_ids\":     padded_targets.tokens,\n",
    "        \"padding_mask\":   padded_inputs.padding_mask,\n",
    "        \"attention_mask\": ~padded_inputs.padding_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "904bdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(\n",
    "    dataset: Dataset,\n",
    "    batch_size: int,\n",
    "    shuffle: bool = True,\n",
    "    drop_last: bool = False,\n",
    "    collate_fn=None,\n",
    "    num_workers: int = 0,\n",
    ") -> DataLoader:\n",
    "    \"\"\"\n",
    "    Create a DataLoader with optional collate_fn.\n",
    "    \"\"\"\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2544b0",
   "metadata": {},
   "source": [
    "## Optimizers (AdamW from scratch)\n",
    "\n",
    "PyTorch optimizers keep **state** for each parameter (e.g. moment estimates in Adam).\n",
    "In this section you’ll implement **AdamW**, which is Adam + *decoupled* weight decay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab920b",
   "metadata": {},
   "source": [
    "### AdamW state\n",
    "For each parameter tensor `p` we store:\n",
    "- `m`: first moment (EMA of gradients)\n",
    "- `v`: second moment (EMA of squared gradients)\n",
    "- `t`: step counter\n",
    "\n",
    "### Update overview (high level)\n",
    "1) Update moments `m, v`\n",
    "2) Bias-correct them (`m_hat, v_hat`)\n",
    "3) Apply parameter update:\n",
    "   `p -= lr * ( m_hat / (sqrt(v_hat) + eps) + weight_decay * p )`\n",
    "\n",
    "Notes:\n",
    "- This update is **in-place** (mutates `p`).\n",
    "- Gradients should not be modified.\n",
    "- State tensors must match parameter shape/device/dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be4c124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AdamWState:\n",
    "    \"\"\"\n",
    "    Per-parameter AdamW state.\n",
    "\n",
    "    m: first moment\n",
    "    v: second moment\n",
    "    t: step count\n",
    "    \"\"\"\n",
    "\n",
    "    m: torch.Tensor\n",
    "    v: torch.Tensor\n",
    "    t: int\n",
    "\n",
    "\n",
    "def init_adamw_state(p: torch.Tensor) -> AdamWState:\n",
    "    \"\"\"\n",
    "    Initialize AdamW state tensors for a parameter tensor p.\n",
    "\n",
    "    What to create:\n",
    "    - m: zeros like p, same shape/device/dtype\n",
    "    - v: zeros like p, same shape/device/dtype\n",
    "    - t: step counter starting at 0\n",
    "\n",
    "    Notes / requirements:\n",
    "    - Use torch.zeros_like(p) for m and v.\n",
    "    - Do NOT attach gradients to the state (initialize under torch.no_grad()).\n",
    "    - t starts at 0. In adamw_step_, increment t to 1 on the first update *before*\n",
    "      computing bias correction terms (1 - beta1^t) and (1 - beta2^t).\n",
    "    - State tensors must live on the same device as p (CPU vs GPU) and have the\n",
    "      same dtype as p.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "      return AdamWState(m=torch.zeros_like(p), v=torch.zeros_like(p), t=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7eeaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamw_step_(\n",
    "    p: torch.Tensor,\n",
    "    grad: torch.Tensor,\n",
    "    state: AdamWState,\n",
    "    lr: float,\n",
    "    betas: tuple[float, float] = (0.9, 0.999),\n",
    "    eps: float = 1e-8,\n",
    "    weight_decay: float = 0.01,\n",
    ") -> AdamWState:\n",
    "    \"\"\"\n",
    "    In-place AdamW parameter update (updates p).\n",
    "\n",
    "    Algorithm (AdamW):\n",
    "      m = beta1*m + (1-beta1)*grad\n",
    "      v = beta2*v + (1-beta2)*grad^2\n",
    "      m_hat = m / (1 - beta1^t)\n",
    "      v_hat = v / (1 - beta2^t)\n",
    "      p = p - lr * (m_hat / (sqrt(v_hat) + eps) + weight_decay * p)\n",
    "\n",
    "    Requirements:\n",
    "    - Update p in-place.\n",
    "    - Return updated state (with incremented t).\n",
    "    - Do not modify grad.\n",
    "    - Should work for any tensor shape.\n",
    "    \"\"\"\n",
    "    beta1, beta2 = betas\n",
    "    t = state.t + 1\n",
    "    m = beta1 * state.m + (1 - beta1) * grad\n",
    "    v = beta2 * state.v + (1 - beta2) * grad ** 2\n",
    "    m_hat, v_hat = m / (1 - beta1 ** t), v / (1 - beta2 ** t)\n",
    "    p -= lr * (m_hat / (torch.sqrt(v_hat) + eps) + weight_decay * p)\n",
    "    return AdamWState(m=m, v=v, t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf5bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamw_step_many_(\n",
    "    params: list[torch.Tensor],\n",
    "    grads: list[torch.Tensor],\n",
    "    states: list[AdamWState],\n",
    "    lr: float,\n",
    "    betas: tuple[float, float] = (0.9, 0.999),\n",
    "    eps: float = 1e-8,\n",
    "    weight_decay: float = 0.01,\n",
    ") -> list[AdamWState]:\n",
    "    \"\"\"\n",
    "    Apply AdamW to many parameters.\n",
    "\n",
    "    Requirements:\n",
    "    - len(params) == len(grads) == len(states)\n",
    "    - Update each param in-place.\n",
    "    - Return the list of updated states.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        adamw_step_(p, g, s, lr, betas, eps, weight_decay)\n",
    "        for p, g, s in zip(params, grads, states)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b571bd",
   "metadata": {},
   "source": [
    "## Training basics\n",
    "\n",
    "A minimal training step follows the same pattern almost everywhere:\n",
    "\n",
    "1) set model to train mode\n",
    "2) reset gradients\n",
    "3) forward pass\n",
    "4) compute loss\n",
    "5) backward pass\n",
    "6) step optimizer\n",
    "\n",
    "In this exercise you’ll implement a single MSE training step using a standard PyTorch optimizer.\n",
    "Return a Python float loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24c815a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_mse(\n",
    "    model: nn.Module,\n",
    "    batch: tuple[torch.Tensor, torch.Tensor],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    One MSE train step using standard torch optimizer.\n",
    "    \"\"\"\n",
    "    # 1 set model to train mode\n",
    "    model.train()\n",
    "    # 2 reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # 3 forward pass\n",
    "    x, y = batch\n",
    "    preds = model(x)\n",
    "    # 4 compute loss\n",
    "    loss = nn.functional.mse_loss(preds, y)\n",
    "    # 5 backward pass\n",
    "    loss.backward()\n",
    "    # 6 step optimizer\n",
    "    optimizer.step()\n",
    "    # 7 return a float loss value\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb5757",
   "metadata": {},
   "source": [
    "## Parameter initialization\n",
    "\n",
    "Initialization matters because it controls signal and gradient scales at the start of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb996eb7",
   "metadata": {},
   "source": [
    "### Fan-in / fan-out\n",
    "- `fan_in`: number of input connections to a unit\n",
    "- `fan_out`: number of output connections from a unit\n",
    "\n",
    "For a Linear layer weight of shape `(out_features, in_features)`:\n",
    "- `fan_in = in_features`\n",
    "- `fan_out = out_features`\n",
    "\n",
    "### Common schemes\n",
    "- **Xavier / Glorot** (often good for tanh / linear-ish nets):\n",
    "  keeps variance stable across layers when activations are roughly symmetric.\n",
    "- **Kaiming / He** (often good for ReLU-like nets):\n",
    "  accounts for the fact that ReLU zeroes out about half the inputs.\n",
    "\n",
    "In this section you’ll implement Xavier uniform and Kaiming uniform and use them to initialize `nn.Linear`.\n",
    "We also always zero the bias unless explicitly told otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c34eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fan_in_fan_out(weight: torch.Tensor) -> tuple[int, int]:\n",
    "    \"\"\"Compute (fan_in, fan_out) for a weight tensor.\"\"\"\n",
    "    # out = w * in\n",
    "    fan_out, fan_in = weight.shape[0], weight.shape[1]\n",
    "    return fan_in, fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d421c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_uniform_(weight: torch.Tensor, gain: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    In-place Xavier/Glorot uniform init:\n",
    "      bound = gain * sqrt(6 / (fan_in + fan_out))\n",
    "      U(-bound, bound)\n",
    "    \"\"\"\n",
    "    fan_in, fan_out = fan_in_fan_out(weight)\n",
    "    bound = gain * (6 / (fan_in + fan_out)) ** 0.5\n",
    "    weight.uniform_(-bound, bound)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e59d69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_uniform_(weight: torch.Tensor, nonlinearity: str = \"relu\") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    In-place Kaiming/He uniform init.\n",
    "\n",
    "    Follow this common choice:\n",
    "      gain = sqrt(2) for ReLU\n",
    "      std = gain / sqrt(fan_in)\n",
    "      bound = sqrt(3) * std\n",
    "      U(-bound, bound)\n",
    "    \"\"\"\n",
    "    fan_in, _ = fan_in_fan_out(weight)\n",
    "    gain = 2 ** 0.5 if nonlinearity == \"relu\" else 1.0\n",
    "    std = gain / fan_in ** 0.5\n",
    "    bound = 3 ** 0.5 * std\n",
    "    weight.uniform_(-bound, bound)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af69be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear_(layer: nn.Linear, scheme: str = \"xavier\") -> nn.Linear:\n",
    "    \"\"\"\n",
    "    Initialize an nn.Linear in-place.\n",
    "\n",
    "    scheme:\n",
    "      - \"xavier\"\n",
    "      - \"kaiming_relu\"\n",
    "      - \"zero\" (weights and bias = 0)\n",
    "    \"\"\"\n",
    "    if scheme == \"xavier\":\n",
    "        xavier_uniform_(layer.weight)\n",
    "    elif scheme == \"kaiming_relu\":\n",
    "        kaiming_uniform_(layer.weight, nonlinearity=\"relu\")\n",
    "    elif scheme == \"zero\":\n",
    "        nn.init.zeros_(layer.weight)\n",
    "    if layer.bias is not None:\n",
    "        nn.init.zeros_(layer.bias)\n",
    "    return layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot-learning-2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
